{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da81fdb-1607-4dcd-8945-78492d41c20c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96049d01-11e9-4538-9012-57992898281e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Advertools - Crawling a website\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/Advertools/Advertools_Crawl_a_website.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/Open_in_Naas_Lab.svg\"/></a><br><br><a href=\"https://bit.ly/3JyWIk6\">Give Feedbacks</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=Advertools+-+Crawling+a+website:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0bd6e-4a5c-472f-a473-a315e3738936",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #advertools #adviz #crawling #website #analyze #seo #URL #audit #scraping #scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089c7e4-b7a9-48ab-8320-e17847ad3b30",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Elias Dabbas](https://www.linkedin.com/in/eliasdabbas/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ef4a3-a632-4a5f-b5aa-dc3fcde269b8",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-07-20 (Created: 2023-07-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93cd7a5-1d4f-4bc6-94a2-b74461c7f538",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook demonstrates how to crawl a website, starting with one of its pages, and discover and follow all links as well.\n",
    "\n",
    "* Convert a website to a CSV file\n",
    "* Follow links with certain conditions:\n",
    "  * Whether or not a link matches a certain regex\n",
    "  * Whether or not a link contains a certain query parameter(s)\n",
    "* Extract special elements from pages using CSS/XPath selectors\n",
    "* Manage your crawling process with advanced settings (number of concurrent requests, when to stop crawling, proxies, and much more)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84a0cf-6ba8-456a-8b42-1bf63e3a17f2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**References:**\n",
    "\n",
    "- [advertools crawl function](https://advertools.readthedocs.io/en/master/advertools.spider.html)\n",
    "- [advertools advanced crawl strategies](https://advertools.readthedocs.io/en/master/advertools.code_recipes.spider_strategies.html)\n",
    "- [scrapy custom settings](https://docs.scrapy.org/en/latest/topics/settings.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ef3a2-b261-45a8-bd64-52cb78b5f502",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6316a-f6a4-4f16-9894-2af1597bfd4f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Install libraries\n",
    "If running it on naas, run the code below to uninstall (bug) and install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f92c36-8ba1-4a92-977f-bb059d99cdb5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y scrapy attrs\n",
    "# !pip install advertools adviz pandas==1.5.3 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f530c66d-1a5b-47d1-8d80-01f21a83ac3e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d108a-44de-44b4-941f-f12795838c5c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import advertools as adv\n",
    "except ModuleNotFoundError:\n",
    "    !pip install advertools\n",
    "    import advertools as adv\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a9e6f-71c4-4cb2-b9bc-32c23b18c4ba",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Variables\n",
    "\n",
    "- `url_list`: One or more URLs to start crawling from (typically the home page, but not necessarily)\n",
    "- `output_file`: The path to the file where you want to save your crawl data\n",
    "- `follow_links`: Whether or not to follow links on each page that you crawl\n",
    "- `allowed_domains`: A list of domains to iclude in the crawl. By default the URLs in `url_list`, and all sub-domains under them will be included, but you can customize/restric this further\n",
    "- `exclude_url_params`: If a link contains any of those parameters don't follow it\n",
    "- `include_url_params`: If a link contains any of those parameters DO follow it\n",
    "- `exclude_url_regex`: If a link matches this regex don't follow it\n",
    "- `include_url_regex`: If a link matches this regex DO follow it\n",
    "- `css_selectors`: A dictionary of CSS selectors for special data to be extracted from crawled pages\n",
    "- `xpath_selectors`: A dictionary of XPath selectors for special data to be extracted from crawled pages\n",
    "- `custom_settings`: Many optinos are available, some of the important one can be found below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcf1a5-23ce-49ca-aee9-aac7ff28a2e4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "crawl_params = dict(\n",
    "    url_list = ['https://example.com'],\n",
    "    output_file = 'website_crawl_YYYY_MM_DD.jl',  # has to end with .jl\n",
    "    follow_links = True,  # the default is False\n",
    "    allowed_domains = None,\n",
    "    exclude_url_params = None,\n",
    "    include_url_params = None,\n",
    "    exclude_url_regex = None,\n",
    "    include_url_regex = None,\n",
    "    css_selectors = None,\n",
    "    xpath_selectors = None,\n",
    "    custom_settings = {\n",
    "        'LOG_FILE': 'website_crawl_YYYY_MM_DD.log',\n",
    "        'CLOSESPIDER_PAGECOUNT': 0,\n",
    "        'CONCURRENT_REQUESTS_PER_DOMAIN': 8,\n",
    "        'DEFAULT_REQUEST_HEADERS': {},\n",
    "        'DEPTH_LIMIT': 0,\n",
    "        'USER_AGENT': adv.spider.user_agent\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6e918-ae61-4a78-9b71-a6ad5f530f53",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe9992-9fcb-4849-a69e-ced13c995aff",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Crawl the given website given the chosen options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949b9c4-f852-47f5-9889-3ccce1a0100a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv.crawl(**crawl_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550110a8-50b2-49a0-9752-5132256356b9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599df7e-552a-406e-9358-48b911426579",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Read and analyze the crawl DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a8e95-fd71-4602-9a29-ccb4bb52c9e2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "crawldf = pd.read_json(crawl_params['output_file'], lines=True)\n",
    "crawldf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "1b68edcb30da94c5c5b1f9eece671a36a1cc832aa557bd6302f2b647aac96ba7",
   "notebook_path": "Advertools/Advertools_Crawl_a_website.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}