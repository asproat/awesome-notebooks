{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recreational-precipitation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T08:00:35.294800Z",
     "iopub.status.busy": "2021-01-25T08:00:35.294557Z",
     "iopub.status.idle": "2021-01-25T08:00:35.307281Z",
     "shell.execute_reply": "2021-01-25T08:00:35.306468Z",
     "shell.execute_reply.started": "2021-01-25T08:00:35.294775Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-teach",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# LinkedIn - Chat about my latest profile posts\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/LinkedIn/LinkedIn_Chat_about_my_latest_profile_posts.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/Open_in_Naas_Lab.svg\"/></a><br><br><a href=\"https://bit.ly/3JyWIk6\">Give Feedbacks</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=LinkedIn+-+Chat+about+my+latest+profile+posts:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a2cbe-a573-488b-88aa-c505a38b3ef5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #linkedin #profile #post #stats #naas_drivers #content #automation #csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412447a1-7aba-4cdf-afec-b5a94515b619",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Jeremy Ravenel](https://www.linkedin.com/in/jeremyravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb917b60-0d9f-48a0-b916-ce3fa9955437",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-07-26 (Created: 2023-07-24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook enables you to converse inside MyChatGPT about your most recent LinkedIn posts using a CSV file stored in your Naas Lab and a JSON plugin asset. Data is updated and replaced with each run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d93a8-af29-41e3-9fc0-29f2bce7658f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\" role=\"info\" style=\"margin: 10px\">\n",
    "<b>Disclaimer:</b><br>\n",
    "This code is in no way affiliated with, authorized, maintained, sponsored or endorsed by Linkedin or any of its affiliates or subsidiaries. It uses an independent and unofficial API. Use at your own risk.\n",
    "\n",
    "This project violates Linkedin's User Agreement Section 8.2, and because of this, Linkedin may (and will) temporarily or permanently ban your account. We are not responsible for your account being banned.\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-bandwidth",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-christianity",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from naas_drivers import linkedin\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import naas\n",
    "import os\n",
    "import json\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "except:\n",
    "    !pip install wordcloud --user\n",
    "    from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import tiktoken\n",
    "except:\n",
    "    !pip install tiktoken --user\n",
    "    import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-founder",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup variables\n",
    "**Mandatory**\n",
    "\n",
    "[Learn how to get your cookies on LinkedIn](https://www.notion.so/LinkedIn-driver-Get-your-cookies-d20a8e7e508e42af8a5b52e33f3dba75)\n",
    "- `li_at`: Cookie used to authenticate Members and API clients\n",
    "- `JSESSIONID`: Cookie used for Cross Site Request Forgery (CSRF) protection and URL signature validation\n",
    "- `linkedin_url`: This variable stores the LinkedIn profile URL that will be used as an input for the script.\n",
    "\n",
    "**Optional**\n",
    "\n",
    "- `limit`: Number of posts retrieved.\n",
    "- `refresh_interval`: Time in minutes between two updates of the CSV file, which helps prevent excessive calls to the LinkedIn API.\n",
    "- `cron`: cron params for naas scheduler, for information on changing this setting, please check https://crontab.guru/ for information on the required CRON syntax.\n",
    "- `plugin_name`: It represents the name of the plugin.\n",
    "- `plugin_model`: It specifies the model to be used by the plugin.\n",
    "- `plugin_temperature`: It determines the creativity level of the generated content, with higher values resulting in more diverse outputs.\n",
    "- `plugin_max_tokens`: It specifies the number of maximum tokens to be used by the plugin.\n",
    "- `system_prompt_max_tokens`: Indicative limit of the maximum number of tokens allowed in the system prompt.\n",
    "- `output_dir`: This variable represents the name of the output directory.\n",
    "- `csv_file_name`: This variable stores the name of the CSV file that will contain the latest posts.\n",
    "- `image_file_name`: This variable holds the name of the image file that will display the word cloud.\n",
    "- `plugin_file_name`: This variable contains the name of the plugin file that will analyze the posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-necklace",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mandatory\n",
    "li_at = naas.secret.get(\"LINKEDIN_LI_AT\")\n",
    "JSESSIONID = naas.secret.get(\"LINKEDIN_JSESSIONID\")\n",
    "linkedin_url = \"https://www.linkedin.com/in/florent-ravenel/\"  # EXAMPLE \"https://www.linkedin.com/in/myprofile/\"\n",
    "\n",
    "# Optional\n",
    "limit = 5\n",
    "refresh_interval = 60\n",
    "cron = \"0 8 * * *\"\n",
    "plugin_name = \"LinkedIn posts analyzer\"\n",
    "plugin_model = \"gpt-4\"\n",
    "plugin_temperature = 0\n",
    "plugin_max_tokens = 8192\n",
    "system_prompt_max_tokens = 2084\n",
    "output_dir = \"linkedin_outputs/latest_posts/\"\n",
    "csv_file_name = \"posts_data.csv\"\n",
    "image_file_name = \"wordcloud.png\"\n",
    "plugin_file_name = \"posts_analyzer_plugin.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-prior",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba2c33-3392-4765-a44c-f25ae6c13492",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Define output paths\n",
    "Create the output directory and define paths for the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293c7b0-db2c-402a-a9a9-3923483bb8fd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if directory exists and create it if not\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "# Generate outputs files path\n",
    "csv_file_path = os.path.join(output_dir, csv_file_name)\n",
    "image_file_path = os.path.join(output_dir, image_file_name)\n",
    "plugin_file_path = os.path.join(output_dir, plugin_file_name)\n",
    "print('📂 CSV file path:', csv_file_path)\n",
    "print('📂 Image file path:', image_file_path)\n",
    "print('📂 Plugin file path:', plugin_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8dcc0-6963-4aa1-8583-c5c1058c7c49",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get data\n",
    "Retrieve the most recent posts from LinkedIn, establishing a limit to prevent transferring an overwhelming amount of data to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0d82f-c939-4fde-a5b0-d5577cf081a1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_last_posts(\n",
    "    li_at,\n",
    "    JSESSIONID,\n",
    "    linkedin_url,\n",
    "    limit,\n",
    "    file_path,\n",
    "    refresh_interval\n",
    "):\n",
    "    # Init\n",
    "    df = pd.DataFrame()\n",
    "    update_data = True\n",
    "    \n",
    "    # Check if output already exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Read file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Assess if LinkedIn API can be invoked based on the last call.\n",
    "        # To emulate human interaction, we must avoid making excessive calls to the LinkedIn API. Overdoing this could result in being banned.\n",
    "        if len(df) > 0:\n",
    "            if \"DATE_EXTRACT\" in df.columns:\n",
    "                # Manage calls to API\n",
    "                last_update_date = df.loc[0, \"DATE_EXTRACT\"]\n",
    "                time_last_update = datetime.now() - datetime.strptime(last_update_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "                minute_last_update = time_last_update.total_seconds() / 60\n",
    "                if minute_last_update < refresh_interval:\n",
    "                    update_data = False\n",
    "                    print(f\"🛑 Nothing to update. Last update done {int(minute_last_update)} minutes ago.\")\n",
    "                    \n",
    "    if update_data:\n",
    "        # Get last posts\n",
    "        df = linkedin.connect(li_at, JSESSIONID).profile.get_posts_feed(linkedin_url, limit=limit)\n",
    "        # Save last posts in CSV\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(\"💾 Dataframe successfully saved:\", file_path)\n",
    "    return df\n",
    "\n",
    "df_posts = get_last_posts(li_at, JSESSIONID, linkedin_url, limit, csv_file_path, refresh_interval)\n",
    "print(\"✅ Row fetched:\", len(df_posts))\n",
    "df_posts.head(limit)\n",
    "\n",
    "# Share output with naas\n",
    "data_link = naas.asset.add(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3d4dd-7d04-4730-8e81-805bb6a905ad",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create image\n",
    "Creating a word cloud is useful as it visually represents the frequency or importance of words in a text, providing a quick and insightful overview of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e5e72-f36c-4d34-855b-ee8162ad3957",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the text variable\n",
    "text = \" \".join(text for text in df_posts.astype(str).TEXT)\n",
    "\n",
    "# Creating word_cloud with text as argument in .generate() method\n",
    "word_cloud = WordCloud(\n",
    "    collocations=False,\n",
    "    background_color=\"white\",\n",
    "    width=1200,\n",
    "    height=600\n",
    ").generate(text)\n",
    "\n",
    "# Display the generated Word Cloud\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Save your image in PNG\n",
    "word_cloud.to_file(image_file_path)\n",
    "print(\"💾 Image successfully saved:\", image_file_path)\n",
    "\n",
    "# Share output with naas\n",
    "image_link = naas.asset.add(image_file_path, params={\"inline\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8163ce-269e-4b30-996f-34c7266ee354",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create MyChatGPT plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e19bc6-5dfa-4902-baae-0fd385f4336d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Prepare data\n",
    "Refine the dataframe for use in the plugin to prevent passing excessive data and tokens to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5300cdbd-614b-4cf7-b3d1-3ce040c79813",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_plugin_data(df):\n",
    "    # Keep column\n",
    "    to_keep = [\n",
    "        \"POST_URL\",\n",
    "        \"AUTHOR_NAME\",\n",
    "        \"PUBLISHED_DATE\",\n",
    "        \"TITLE\",\n",
    "        \"TEXT\",\n",
    "        \"VIEWS\",\n",
    "        \"LIKES\",\n",
    "        \"COMMENTS\",\n",
    "        \"SHARES\",\n",
    "        \"ENGAGEMENT_SCORE\"\n",
    "    ]\n",
    "    df = df[to_keep]\n",
    "    \n",
    "    # Filter\n",
    "    df = df[df[\"VIEWS\"].astype(int) > 0]\n",
    "    \n",
    "    # Multiply ENGAGEMENT_SCORE by 100 and drop the original column\n",
    "    df[\"ENGAGEMENT_%\"] = df[\"ENGAGEMENT_SCORE\"] * 100\n",
    "    df = df.drop(columns=[\"ENGAGEMENT_SCORE\"])\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "data = create_plugin_data(df_posts)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f094412-995b-4c20-8172-25ac7b7f9f55",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Engineer system prompt\n",
    "We used Playground to refined it: https://platform.openai.com/playground?mode=chat&model=gpt-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1dc01-6ac4-4429-b1cd-56d9b0fda7bd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"Act as a Social Media Analyst Asssitant. Your job is to help you unravel the story behind the user LinkedIn posts' performance. \n",
    "You can dive deep into the data and gather insights that can help boost the user LinkedIn strategy.\n",
    "You can help the user understand which posts are getting the most views, likes, comments, and shares. \n",
    "You can also analyze the engagement of each post and see how it correlates with different factors. \n",
    "When you refer to a post, create href in markdown format so that the user can go to the post you mention by clicking on the markdown href link in a new tab.\n",
    "But that's not all! You can also help identify trends over time, find out the best time to post, best post to do next, understand the impact of different post types, and much more. \n",
    "The possibilities are endless, be creative!\n",
    "Now, let's get started. Here's the data from the user latest LinkedIn posts: \n",
    "{data.to_string()}.\n",
    "Let's dive in and discover the stories the data is waiting to tell! \n",
    "The fist message should be about presenting yourself with maximum 5 bullet points and displaying the worldcloud: {image_link}\n",
    "Then, wait for the first answer from the user, and then start with a first high level analysis.\n",
    "Here is the link to download the data in csv: {data_link}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6353742-7636-434b-95a2-c018b4dabb07",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Check tokens count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2d231-8ef0-4572-9ebc-f47e5858fcd0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "system_prompt_tokens = num_tokens_from_string(system_prompt, \"cl100k_base\")\n",
    "if system_prompt_tokens > system_prompt_max_tokens:\n",
    "    print(\"⚠️ Be carefull, your system prompt looks too big. Tokens:\", system_prompt_tokens)\n",
    "else:\n",
    "    print(\"✅ System prompt tokens count OK:\", system_prompt_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5b374-cc7c-46be-b744-6e6bb7fab3ce",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Generate plugin\n",
    "Plugin must be a JSON file with mandatory keys name, model, temperature, max_tokens and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63634c44-bd17-4431-a6b1-282f4c4cc1f1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create json\n",
    "plugin = {\n",
    "    \"name\": plugin_name,\n",
    "    \"model\": plugin_model,\n",
    "    \"temperature\": plugin_temperature,\n",
    "    \"max_tokens\": plugin_max_tokens,\n",
    "    \"prompt\": system_prompt,\n",
    "}\n",
    "\n",
    "# Save dict to JSON file\n",
    "with open(plugin_file_path, \"w\") as f:\n",
    "    json.dump(plugin, f)\n",
    "print(\"💾 Plugin successfully saved:\", plugin_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-sucking",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904d439-418a-4be7-980c-6a6f945c503e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create asset\n",
    "You can now use in your MyChatGPT by copy/pasting the URL after the command `/use `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96830a43-cd0c-4e40-85bd-a4fb11423ba1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "naas.asset.add(plugin_file_path, params={\"inline\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f01b9b-2f42-473a-a8b2-14b4e0f632b2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Add scheduler\n",
    "Schedule your notebook with the naas scheduler feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07981f66-32ef-4916-8eb3-042d7144f464",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "naas.scheduler.add(cron=cron)\n",
    "\n",
    "# to de-schedule this notebook, simply run the following command:\n",
    "# naas.scheduler.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "8ba17ce043515c04a2f3081afbd6904e272b708e06388b566b4a286a2fd7d785",
   "notebook_path": "LinkedIn/LinkedIn_Chat_about_my_latest_profile_posts.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}